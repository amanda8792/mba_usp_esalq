{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3254a3d5-8649-44c8-8e77-624165bb2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.cm import rainbow\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f65b4f-df10-431e-8ee7-5fe1d2094a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540dab18-321d-43c6-b4f6-249e870fc97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('application_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e92395-b567-4a51-9547-37a4e5d77c55",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6683f4b-daaa-4e53-850c-37054582d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 01 - Tratamento e limpeza dos dados nulos\n",
    "\n",
    "docs_colunas = ['FLAG_DOCUMENT_' + str(i) for i in range(2, 22)]\n",
    "df['NUM_DOCS_APRESENTADOS'] = df[docs_colunas].sum(axis=1)\n",
    "flag_docs_colunas = [col for col in df.columns if col.startswith('FLAG_DOCUMENT_')]\n",
    "df_exclusao_cols = df.drop(columns=flag_docs_colunas)\n",
    "df = df_exclusao_cols\n",
    "\n",
    "# Exclusão de colunas com valores nulos\n",
    "\n",
    "def excluir_colunas_nulas(df, percentual):\n",
    "    dados_faltantes = df.isnull().mean() * 100\n",
    "    col_para_apagar = dados_faltantes[dados_faltantes > percentual].index.tolist()\n",
    "    return col_para_apagar\n",
    "\n",
    "percentual = 0\n",
    "col_para_apagar = excluir_colunas_nulas(df, percentual)\n",
    "\n",
    "# Exclui as colunas identificadas\n",
    "df_exclusao_colunas = df.drop(columns=col_para_apagar)\n",
    "df = df_exclusao_colunas\n",
    "\n",
    "# Exclusão de colunas de categoria única\n",
    "\n",
    "columns_to_drop = ['FLAG_MOBIL',\n",
    "                   'FLAG_EMP_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL','REG_REGION_NOT_WORK_REGION',\n",
    "                   'REG_REGION_NOT_LIVE_REGION','REG_CITY_NOT_WORK_CITY','REG_CITY_NOT_LIVE_CITY']\n",
    "df = df.drop(columns_to_drop,axis=1)\n",
    "\n",
    "# Exclusão dos valores 'XNA' (essencialmente nulos) em CODE_GENDER\n",
    "\n",
    "df = df[df['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "# Conversao de algumas colunas para anos\n",
    "\n",
    "# Colunas que terão o sinal removido (valores absolutos)\n",
    "colunas_para_remover_sinal = ['DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH']\n",
    "df[colunas_para_remover_sinal] = df[colunas_para_remover_sinal].abs()\n",
    "\n",
    "# Engenharia de atributos\n",
    "df['IDADE'] = df['DAYS_BIRTH'] // 365\n",
    "df['ANOS_TRABALHADOS'] = df['DAYS_EMPLOYED'] // 365\n",
    "df['ANOS_REGISTRO'] = df['DAYS_REGISTRATION'] // 365\n",
    "df['ANOS_PUBLICACAO_ID'] = df['DAYS_ID_PUBLISH'] // 365\n",
    "\n",
    "# Remover colunas originais\n",
    "df = df.drop(colunas_para_remover_sinal, axis=1)\n",
    "\n",
    "#  Devido a uma alta correlação, decidi remover Region_Rating_Client_With_City\n",
    "\n",
    "column_to_drop = ['REGION_RATING_CLIENT_W_CITY']\n",
    "df1 = df.drop(column_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251c267-4c80-4478-9d44-af1661338774",
   "metadata": {},
   "source": [
    "## Random Forest 1 - Base após EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c5d2df1-04f8-446c-80ce-efe5fd95f5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 307507 entries, 0 to 307510\n",
      "Data columns (total 17 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   SK_ID_CURR                   307507 non-null  int64  \n",
      " 1   TARGET                       307507 non-null  int64  \n",
      " 2   CNT_CHILDREN                 307507 non-null  int64  \n",
      " 3   AMT_INCOME_TOTAL             307507 non-null  float64\n",
      " 4   AMT_CREDIT                   307507 non-null  float64\n",
      " 5   REGION_POPULATION_RELATIVE   307507 non-null  float64\n",
      " 6   FLAG_WORK_PHONE              307507 non-null  int64  \n",
      " 7   FLAG_PHONE                   307507 non-null  int64  \n",
      " 8   REGION_RATING_CLIENT         307507 non-null  int64  \n",
      " 9   HOUR_APPR_PROCESS_START      307507 non-null  int64  \n",
      " 10  LIVE_REGION_NOT_WORK_REGION  307507 non-null  int64  \n",
      " 11  LIVE_CITY_NOT_WORK_CITY      307507 non-null  int64  \n",
      " 12  NUM_DOCS_APRESENTADOS        307507 non-null  int64  \n",
      " 13  IDADE                        307507 non-null  int64  \n",
      " 14  ANOS_TRABALHADOS             307507 non-null  int64  \n",
      " 15  ANOS_REGISTRO                307507 non-null  float64\n",
      " 16  ANOS_PUBLICACAO_ID           307507 non-null  int64  \n",
      "dtypes: float64(4), int64(13)\n",
      "memory usage: 42.2 MB\n",
      "base para árvore:  None\n"
     ]
    }
   ],
   "source": [
    "# Selecionar colunas numéricas (int64 e float64)\n",
    "colunas_numericas = df1.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "df_arvore_1 = df1[colunas_numericas]\n",
    "print('base para árvore: ', df_arvore_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6f4fe6-34c2-4f23-8411-73ad5b10c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9192\n",
      "Precisão: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "Matriz de Confusão:\n",
      "[[84803     2]\n",
      " [ 7448     0]]\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     84805\n",
      "           1       0.00      0.00      0.00      7448\n",
      "\n",
      "    accuracy                           0.92     92253\n",
      "   macro avg       0.46      0.50      0.48     92253\n",
      "weighted avg       0.85      0.92      0.88     92253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separando os dados entre variáveis explicativas (X) e a variável alvo (y)\n",
    "X = df_arvore_1.drop(columns=['TARGET'])  # Substitua 'TARGET' pela coluna alvo correta\n",
    "y = df_arvore_1['TARGET']\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Criando o modelo de Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Avaliação dos resultados\n",
    "print(f'Acurácia: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print(f'Precisão: {precision_score(y_test, y_pred):.4f}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_test, y_pred):.4f}')\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2164b-0ed3-4044-8811-654f74d20979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tentativa de melhoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784dc28f-773d-473a-b315-8664f9d8ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Etapa 02 - Criação do modelo Random Forest com melhorias\n",
    "# Separação das features e target\n",
    "X = df_arvore_1.drop(columns=['TARGET'])  # Supondo que 'TARGET' seja a variável-alvo\n",
    "y = df_arvore_1['TARGET']\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Criando o modelo de Random Forest com balanceamento de classes\n",
    "random_forest = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Parâmetros a serem ajustados no GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Aplicando o GridSearch com validação cruzada\n",
    "grid_search = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Treinando o modelo\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhor modelo encontrado\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Avaliação dos resultados\n",
    "print(f\"Melhores parâmetros: {grid_search.best_params_}\")\n",
    "print(f'Acurácia: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print(f'Precisão: {precision_score(y_test, y_pred):.4f}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_test, y_pred):.4f}')\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57cbcd5-c839-49c9-8767-0d3f57a8c624",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97134ef-cf6a-431a-9565-d300bbaf0e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a15de1-aa6f-437a-a7d7-05bacbe7c489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d466b50-231c-4c9b-8dbc-d26be76e4f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42da4166-b57c-4238-887e-b8967d4be3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d110b-0aca-4b10-9f4e-e57be9b1da51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ac0949-f15d-4079-b8f2-7aca564b585d",
   "metadata": {},
   "source": [
    "## Árvore 2 - Base completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c20294-6f7e-4385-bbb0-9748e31f23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "df2 = pd.read_csv('application_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b147b77d-4385-4982-a7c3-bc55666cc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_test = df2.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "alpha = 0.05\n",
    "significant_variables = []\n",
    "\n",
    "for variable in variables_to_test:\n",
    "    # Extrair dados para os grupos de inadimplência (TARGET = 1) e não inadimplência (TARGET = 0)\n",
    "    data_default = df2[df2['TARGET'] == 1][variable].dropna()  # Remover valores nulos\n",
    "    data_no_default = df2[df2['TARGET'] == 0][variable].dropna()  # Remover valores nulos\n",
    "\n",
    "    # Realizar o teste t para duas amostras\n",
    "    t_statistic, p_value = stats.ttest_ind(data_default, data_no_default, equal_var=False)\n",
    "\n",
    "    # Verificar significância\n",
    "    if p_value < alpha:\n",
    "        significant_variables.append(variable)\n",
    "\n",
    "# Criar um novo DataFrame apenas com as variáveis significativas\n",
    "df2 = df2[significant_variables]\n",
    "\n",
    "def identify_columns_to_drop(df, percentage):\n",
    "    missing_percentage = df.isnull().mean() * 100\n",
    "    columns_to_drop = missing_percentage[missing_percentage > percentage].index.tolist()\n",
    "    return columns_to_drop\n",
    "\n",
    "percentage = 0\n",
    "columns_to_drop = identify_columns_to_drop(df2, percentage)\n",
    "\n",
    "# Exclui as colunas identificadas\n",
    "df2 = df2.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1364e1d-099e-4692-a3fb-6ebbb23df90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9193\n",
      "Precisão: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "Matriz de Confusão:\n",
      "[[84805     1]\n",
      " [ 7448     0]]\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     84806\n",
      "           1       0.00      0.00      0.00      7448\n",
      "\n",
      "    accuracy                           0.92     92254\n",
      "   macro avg       0.46      0.50      0.48     92254\n",
      "weighted avg       0.85      0.92      0.88     92254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separando os dados entre variáveis explicativas (X) e a variável alvo (y)\n",
    "X = df2.drop(columns=['TARGET'])  # Substitua 'TARGET' pela coluna alvo correta\n",
    "y = df2['TARGET']\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Criando o modelo de Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Treinando o modelo com os dados de treino\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# Avaliação dos resultados\n",
    "print(f'Acurácia: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print(f'Precisão: {precision_score(y_test, y_pred):.4f}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred):.4f}')\n",
    "print(f'F1-Score: {f1_score(y_test, y_pred):.4f}')\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938554a-af76-45df-9ca8-ea49ec54101a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac00f7b2-cf01-4801-9b6a-2df5d092e51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4ac61-18c3-4792-be0f-acf1413c8cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d36e9-cdcf-4b95-913f-fb0428f00a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9571f35f-6d87-4d4c-b761-91f0a012cfef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
